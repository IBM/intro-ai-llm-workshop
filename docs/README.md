# Introduction

## AI and Windows Granite Workshop

Welcome to our workshop! In this workshop we'll be using the open-sourced IBM Granite AI foundation models for a number of use cases that demonstrates the value of generative AI.

The goals of this workshop are:

* Installing Open Source AI tools on your own Windows 11 laptop (Mac instructions to follow soon) to run AI locally.
* Running LLM models via command line
* Running LLM models with a UI interface
* Try to improve results with Retrieval-Augmented Generation 
* Running with a multimodal LLM 

### About this workshop

The introductory page of the workshop is broken down into the following sections:

* [Agenda](#agenda)
* [Compatibility](#compatibility)
* [Technology Used](#technology-used)
* [Credits](#credits)

## Agenda

|  |  |
| :--- | :--- |
| [Pre-Work](pre-work/README.md) | Prerequisites for the workshop |
| [Lab 1: Command-Line Ollama](lab-1/README.md) | Lab 1 |
| [Lab 2: Using Open-WebUI Interface](lab-2/README.md) | Lab 2 |
| [Lab 3: Graphics and MultiModal LLM](lab-3/README.md) | Lab 3 |

## Compatibility

This workshop has been tested on the following platforms:

* **Windows 11** (Ideally with at least 16GB of memory, but 8GB memory can work with smaller models.
* (MacOS instructions included)

## Technology Used

* IBM Granite Models
* Open Source Ollama
* Open source Open-WebUI

## Credits

* [James Busche](https://github.com/jbusche)
* [Yi-Hong Wang](https://github.com/yhwang)
